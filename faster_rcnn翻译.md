# faster rcnn 翻译

## faster RCNN:包含RPN（区域推荐网络）的趋向于实时的物体检测器

 							作者：Shaoqing Ren, Kaiming He, Ross Girshick（fast rcnn anthor), and Jian Sun



# 概要

最新的物体检测器依赖于区域推荐算法去假设物体的位置，它优于SPPnet和Fast RCNN的地方在两个方面：1.减少了测试阶段网络的运行时间；2. --把区域推荐计算暴露成一个瓶颈-- 

在这个工程中， 我们一个RPN网络来和检测网络一同共享了整个图片的卷积特征。因此能得到近乎无成本的区域推荐能力。一个RPN是一个全卷积网络，它同时预测物体边框和在每个位置的边框得分。RPN被训练成端到端的网络以便去生成一些高质量的推荐区域,  被用于fast RCNN去检测物体。通过共享卷积特征我们进一步的把fast RCNN和RPN融合进一个网络----用最近流行的神经网络术“注意力”机制，RPN元素告诉整合的神经网络去哪里寻找。对于很深的VGG模型，在GPU上，我们的检测器可以达到帧速率为5fps的速度并且可以实现最好的检测效果在PASCAL VOC 2007, 2012 和 MS COCO数据集



# 1. 介绍

​	最近在物体检测方面的进步是由于区域推荐方法的成功来推动的（比如说基于区域的卷积神经网络R-CNNs）。即是最初的RCNN计算成本是非常昂贵的，但由于共享卷积交叉推荐技术的出现使其成本大大降低。最新的体现就是：当忽略区域推荐的耗时时，fast RCNN通过很深的神经网络，实现了近乎实时的物体检测能力。现在区域的产生成为了实时监测的测试计算瓶颈。

​	传统的区域检测方法依赖于底层的特征和经济的推断方案。选择性搜索，这是最流行的一种方法，它基于低水平的特征工程，以贪婪模式的一步步融合了超像素（小尺度的区域）。但当对比与后面有效的物体检测网络，选择性搜索方法太慢了，在GPU上每张图片需要2秒钟。边框方法需要0.2秒，但还是很慢。

​	值得提出的一点，传统的区域检测方法在搜素是用的是CPU，但fast RCNN利用了GPU，让这个耗时时间比较变得不平等，这可能是一个工程方法去解决耗时问题，但是反复的应用GPU会忽视这个下游的物体检测网络，因此失去了很多共享计算的机会

​	在这片论文中，我们展示了一个算法上的改变----用深度神经网路来计算推荐区域----这会产生一个精妙且有趣的方法，在检测网络的计算的基础上，这个区域计算可以近乎是无成本的。最后我们引进新颖的RPN，它和最新的物体检测网络共享了卷积层。通过在测试时共享卷积层，计算区域所需耗时非常小，可以达到每张图片10ms。

​	鉴于我们的观测，这个卷积特征网络映射（被用于基于区域的检测器，像Fast RCNN） 也可以被用于产生推荐区域。在这些卷积特征层的最上层，我们通过加一点额外的卷积层来构造一个RPN，在特征区域的网格上的每一个位置（像素点），同时产生一些边框回归和对象分数。这个RPN因此是一个全联接层网络（FCL），它可以被训练成一端到端的检测推荐区域产生器。

​	通过一系列的纵横比（aspect ratios）和尺度（scales），RPN可以有效的预测出大量的候选推荐区域。

![image-20181116192434070](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/image-20181116192434070.png)



图片一：对于解决多尺度和大小的不同策略。（a)金字塔式的图片和特征映射被建立，这个分类器会运行所有的尺度。(b) 运行在特征映射上的多尺度的金字塔式的过滤器。（c) 我们使用的是在回归方程上使用涉及边框的金字塔

​	图片金字塔结构（a)、金字塔过滤器结构(b)、我们引进一个新的词汇'锚点'方框作为多尺度和纵横比的参考。我们的策略可以被认为是涉及回归的金字塔结构，它避免了列举多尺度、纵横比的图片或者过滤器。在用单尺度的图像进行训练和测试时，模型会运行的很好，这样也有利于运行速度。

​	为了去整合RPNs和Fast RCNN 物体检测网络，我们推荐一种训练策略，它交替的（fine-tuning）调整区域推荐任务和物体检测任务，--同时保持了推荐区域的固定--。这种策略可以快速收敛并且通过在两个任务之间共享卷积特征，产生一个整合、一体化的网络结构。

​	我们在PASCAL VOC 基准上综合的评价我们的方法，带有RPN的fast RCNN比基于搜索性选择的fast RCNN准确率更高， 同时我们的方法在测试阶段免除了近乎所有的搜索性选择带来的计算负担。用于区域推荐所需时间只要10毫秒。用于很深的网络模型，我们在GPU上仍然可以达到帧速率为5fps的速度，因此这是一个集速度与精度于一体的实用的物体检测系统。

​	这个RPN和faster RCNN框架已经被用于各种其他的方法，比如：3D物体检测、基于部分的物体检测、实例分割和图片文字描述。我们这种快速且有效的方法也被用于商业系统例如Pinterests。

​	在ILSVRC和COCO 2015竞赛中，faster rcnn 和 RPN是 几个图片比赛第一名的基础配置。RPN可以从图片数据中完全的学习到推荐区域，可以很容易且很好的利用很深、很抽象的表示特征。从以上可以看出RPN和Faster RCNN不仅是节约计算成本，也是可以提高计算准确率的。



# 2 相关工作

​	**物体推荐（Object Proposals）**，这是一个物体推荐方法里的大的专业词汇。包括基于成组的超像素方法（如选择性搜索selective search）和滑动窗口方法(如EdgeBoxes) 都会使用物体推荐方法。它可以被选择做为一种外部模块且独立于检测器。



​	**用于物体检测的深度网络**，区域卷积神经网络（R-CNN）方法端到端的训练CNNs去把候选区域分类为物体类别或者背景。R-CNN主要是起到分类器的作用，它并没有预测到物体边框（除了通过边框回归调整位置）。它的准确性取决于物体推荐模块的性能。几篇论文已经提到用深度网络去预测边框。在OverFeat方法中，一个全联接层被训练用于预测物体坐标对于单个物体的定位任务。把这个全联接层然后变换成一个用于检测多个类别的客体的卷积层，叫做多边框。这种多边框（MultiBox)方法从网络的最后一个全联接层产生多个推荐区域同时预测多个未知的方框，泛化了这个OverFeat的单个方框方法。这些未知类别的方框用来成为R-CNNs的推荐区域。这个多边框推荐网络可以用来对单个图片进行裁剪或者多张大图片裁剪（如244 x 244），对比我们的全联接层策略，多边框方法没有在推荐层和检测层共享特征。我们会在下面结合我们的方法进一步讨论Overfeat和MultiBox，同步与我们的方法，这个DeepMask深度掩码方法是用于语义级别的区域推荐。

​	共享卷积层的计算，一直在吸引越来越多的关注，以获得有效而准确的视觉识别。OverFeat计从一种图片金字塔中计算卷积特征用于后面的定位、分类和检测。Adaptively-sized pooling(SPP)它基于共享卷积特征映射可以用来进行基于区域的物体检测和语义分割。基于共享卷积特征，Fast R-CNN可以进行端到端的检测器训练，有着很好的准确性和速度。

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-11-19_10-31-37.png)

​	图二：Faster R-CNN 是一个单一、整合的用于物体检测的网络，这个RPN模块可以看成这个网络的’注意力‘结构

# 3 FASTER R-CNN

​	我们的物体检测系统，称为Faster R-CNN,由两个模块组成。第一个模块是深度卷积网络，用来推荐区域。第二个模块是Fast R-CNN检测器，它使用推荐区域。整个系统是一个统一的物体检测网络（如图二）。用最新的神经网络术语“注意力”机制，这个RPN模块告诉Fast R-CNN模块去哪里寻找检测对象。在3.1章节我们将引进这个区域推荐网络的介绍和属性。在3.2章节我们将形成通过共享特征来训练两个模块的算法。



## 3.1 区域推荐网络（RPN）

​	RPN把任何大小的图片作为输入，并且输出一系列长方形物体区域，并带有相应的分数，因为我们的最终目标是和Fast RCNN共享计算，我们假设两种网络共享一系列公共的卷积层。

​	为了产生推荐区域，我们在最后一个共享卷积层输出的卷积特征图上 滑动一个小网络。该小网络将输入卷积特征映射的n×n空间窗口作为输入。每一个滑动窗口都被映射到一个低维特征。这个特征是被应用于两个全联接层----分类层和回归层。本论文中我们用的是3x3，注意在输入图片上有效感受野很大（VGG下有228个像素）。 这个迷你网络在图3（左）中的单个位置示出。 请注意，由于迷你网络以滑动窗口方式运行，因此在所有空间位置共享完全连接的层。 这种架构自然地实现了n×n卷积层，接着是两个兄弟1×1卷积层（分别用于reg和cls）。

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-11-19_13-22-46.png)

### 3.1.1 锚点 

​	对于每一个滑动窗口的位置，我们同时预测多个推荐区域，每个位置最多可能的推荐区域数量用k表示。所以这个回归层针对k个方框，有4k个输出。分类层有2k个分数输出预测这个前景和背景的可能性。这k个推荐区域是相关的k个方框的参数化，我们称它们为锚点。一个锚点是我们讨论的滑动窗口的中心，滑动窗口的大小与标度和纵横比相关。默认情况下，我们使用3个标量和3个纵横比，即在每个位置会产生9个锚点。对于一个大小为W x H的feature map（一般大约为2400），总共会有WHk个锚点。

> 为了简化，我们用softmax用来二分类操作、用logistic用来回归操作

#### 锚点的平移不变性

​	我们方法的一个重要属性是他有着平移不变性。不管是锚点还是这个计算锚点区域的函数。如果在一张图片上将其中一个物体移动，这个推荐区域和对应的函数也应该有相对应的移动。平移不变应是我们方法的保证。作为对比the MulltiBox方法使用k均值聚类去产生800个锚点，没有平移不变性，所以他不能保证如果图片中物体移动，会产生相同的推荐区域。

​	这个平移不变性也会减少模型的大小，MultiBox有（4+1)x800维度的全联接输出层，然而我们的方法只需(4+2)x9维度的卷积输出层（在k=9的情况下）。因此我们的输出层有$2.8*10^4$个参数（512 x (4+2) x 9 for VGG19), MultiBox的输出层有$6.1*10^6$个参数。我们希望这种方法可以更有效的避免过拟合。

#### 多标量锚点做为回归参数

​	我们锚点的设计代表了一种新型的策略。如图一所示，这里有两种多尺度预测的方法。第一种方法是基于图片/特征金字塔(基于DPM(可变形的组件模型)和基于CNN方法)， 这种方法非常耗时。第二种方法是在feature map上使用多标量的滑动窗口。

​	作为比较，我们基于锚点的方法是建立在锚点金字塔结构之上的，更加有效。我们的方法参考多尺度和纵横比的锚框对边界框进行分类和回归。 它仅依赖于单个尺度的图像和特征图，并使用单个尺寸的过滤器（在特征图上滑动窗口）。 我们通过实验证明了该方案对于解决多种尺度和尺寸的影响。由于这种基于锚点的多尺度设计，我们可以简单地使用在单尺度图像上计算的卷积特征，这也可以通过fast R-CNN检测器来完成。 多尺度锚的设计是共享特征的关键组件，无需额外成本来解决尺度问题。。



### 3.1.2 损失函数

在一个mini-batch里面，为了训练RPN，我们为每个锚点设计一个二分类标签（前景、背景）。我们把以下两种锚点设计为正标签：1.与**一种**实际物体边框有最高重叠度(IoU Intersection over Union)的锚点  2.对于**任何的**实际物体边框IoU超过0.7的锚点。主要单个实际物体边框可能对应着多个锚点，通常第二种情况更可能产生正样本。但是为了防止第二种情况发现不了正样本，我们也采用第一种情况。我们把一个对于任何实际的边框**IoU都小于0.3的看成负标签**。那些非正且非负标签的锚点不会成为下一阶段的训练目标。

通过这些定义，我们定义一个批次的损失值如下：

​	$L({p_i}, {t_i}) = \frac{1}{N_{cls}}\sum L_{cls}(p_i, p_i^*) + \gamma\frac{1}{N_{reg}}\sum p_i^*L_{reg}(t_i, t_i^*)$

$i 代表每一个锚点 $

$ p_i是锚点i是前景的可能性 p_i^*是实际是否是前景 0或者1$

$t_i是锚点i的4个位置参数，t_i^*是联系到一个正标签锚点的实际方框的4个参数$ 

$L_{cls}是log函数。L_{reg}是哈勃损失函数 $

$p_i^*L_{reg}表示只有是正标签时才被激活$

$$cls项由小批量mini.batch大小（即，N_{cls} = 256）标准化，并且reg项由锚位置的数量标准化（即，N_{reg}~2,400）。  $$

$默认情况下，为了平衡两个损失函数，我们设置λ= 10，因此cls和reg项的大致相等$

其实上面的正则化也可以被简化

##### 在回归损失函数计算时，如何保证每个锚点能找到与它对应的ground-truth box??



对于边框回归，我们变换四个坐标参数

#### 						------->使x值接近$x^*$

$t_x = (x - x_a) / w_a, t_y = (y - y_a) / h_a$

$t_w = log(w/w_a), t_h = log(h/h_a)$

$t_x^* = (x^*-x_a)/w_a,  t_y^{*} = (y^*-y_a)/h_a$

$t_w^* = log(w^*/w_a), t_h = log(h^*/h_a)$



$x, y, w 和 y 表示这个边框的中心坐标和宽、高。$

$x,x_a,x^*分别代表预测框、锚点框和实际框(y,w,h同理​$



然而，我们的方法实现了与之前的基于感兴趣区域（Region of Interst)方法不同，我们的边框回归对任意大小的RoIs执行特征池化操作。**这个回归的权重是在所有区域中共享的**。在我们的方程中，这个被用于feature map中的卷积核都是有相同的空间大小(3x3)。为了处理不同的大小，一系列 k个回归器被学习。每个回归器都是对应一标量(scale)和纵横比(aspect ratio)，**这k个回归器没有共享权重。**因此，幸亏这个锚点设计，它是可能的对于一个固定大小的特征，也可以预测不同大小的方框。

### 3.1.3 训练RPN

​	RPN可以通过随机梯度下降和反向传播来进行端到端的训练。为了平衡正负样本的数量（通常副样本极多）我们随机抽取256个锚点（1:1对于正负样本），去计算损失值。如果正样本没有128个，用负样本补上。

​	我们随机的用均值为0，标准差为0.01的高斯分布来初始化新的层权重。其他的层（比如共享的卷积层）我们用ImageNet分类上的预训练模型，这是一种常见的做法。



## 3.2 用于RPN和Fast RCNN的共享特征

​	目前为止，我们已经描述出怎样去训练一个网络，去产生推荐区域，但没有考虑到后面的CNN检测器如何去使用它们。对于检测网络我们采用fast rcnn，接下来我们将描述一个统一的网络，包含rpn和fast rcnn，共享卷积层。

​	如果，rpn和frcnn都独立的训练，他们将以不同的方式改变卷积层。因此我们希望去开发一种技术去共享卷积层特征，而不是分别的进行网络学习。我们讨论三种方法用于训练网络：

 	1. **交替训练**， 在这个方法里，我们首先训练rpn，然后用推荐区域去训练frcnn，这个被frcnn改变的网络又去训练rpn，反复这个过程，这是一个解决方法被用于本论文的所以实验。
 	2. **近似的联合训练**， 在这个方法中，如图二，在训练时，rpn和frcnn被融入一个网络中。在每一层随机梯度下降时，这个前向传播产生一些推荐区域，在frcnn训练时，这些区域被认为是大小固定的、预先计算的。反向传播如常进行。对于共享性，它的损失值受到rpn和frcnn结合的影响。这种方案易于实施，但是这个解决方案忽略了w.r.t的衍生物。提案框的坐标也是网络响应，因此是近似值。
 	3. **非近似联合训练**。 如上所述，由RPN预测的边界框也是输入的函数。 fast-R-CNN中的RoI池化层接受卷积特征以及预测的边界框作为输入，因此理论上有效的反向传播求解器也应该涉及梯度w.r.t. 框坐标。 在上述近似联合训练中忽略这些梯度。 在非近似联合训练解决方案中，我们需要一个可区分w.r.t框坐标的RoI池层。 这是一个非常重要的问题，并且可以通过“RoI warping”层给出解决方案，这超出了本文的范围。

**4 步交替训练** 在这篇文章中，我们采用四步训练算法通过交替优化去学习共享特征。在第一步，如3.1.3，我们学习rpn，这个网络通过预训练的ImageNet模型初始化，在区域推荐任务中进行端到端的调整，产生推荐区域。在第二步，我们用以上产生的推荐区域去单独训练fast rcnn，这个检测网络也是被ImageNet预训练模型初始化的。目前为止，这两个网络还是没有共享卷积层。第三步，我们用检测器网络去初始化rpn,但我们固定共享的卷积特征层，仅仅对rpn层进行fine-tune。现在这两个网络共享卷积层了。最后，保持这个共享卷积层不变，我们仅仅fine-tune fast rcnn层。就这样，两个网络共享相同的卷积层，形成一个统一的网络。













-- * * * * *--  表示翻译不确定的地方