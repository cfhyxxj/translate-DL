# fast rcnn 翻译

# 概要

​	本文提出了一种快速的基于卷积神经网络的物体检测方法。fast rcnn建立在之前的基础上，用深度网络进行了有效的分类，不仅提高了速度，还增加了准确率。



# 1 介绍

最近，深度卷积网络在图片分类和物体识别上面，已经带来了精准度的提高，比较于图片分类，物体检测是一个更复杂的任务，需要更多复杂的方法去解决。由于它的复杂性，目前的方法训练模型在多阶段，是缓慢且不精美。

​	复杂性的产生是因为检测需要准确的物体位置，产生了两种主要的挑战。第一，大量的候选物体位置（推荐区域）必须被处理。这些推荐区域只提供大约的定位，必须被进一步精调。

​	本文中，我们简化了最新的基于卷积网络的检测器训练流程，提供了一种单阶段的训练算法，它联合的学习了分类物体推荐和对于他们空间位置的精调。

​	这种方法可以训练很深的网络（在VGG16中，比R-CNN快9倍，比SPPnet快3倍）

## 1.1 R-CNN and SPPnet

RCNN有以下几种主要的缺点

- **训练是多阶段的**。RCNN首先通过 log损失fine-tune物体区域推荐的卷积网络，然后，它用SVM处理卷积特征。这些SVM充当物体检测器，取代了通过微调学习的softmax分类器。 在第三个训练阶段，学习边界框回归量。

- **训练是耗时耗空间的**。对于SVM和边框回归训练，在一张图片的每一个推荐区域，特征是被提取出来并写入磁盘

对于非常深的网络，例如VGG16，这个过程需要2.5个GPU天才能获得VOC07 trainval set的5k图像。 这些功能需要数百GB的存储空间。

- **物体检测很慢**。在测试阶段，特征从每个图片中推荐区域中提取，GPU上一张图片需要47s

RCNN之所以慢是因为它对于每一个推荐区域都执行前馈卷积网络传播，没有共享计算。空间金字塔池化网络(SPPnet)通过共享计算加速R-CNN。SPPnet计算整个输入图片形成的卷积特征图，然后用从特征图上提取的特征向量来分类每一个推荐区域。推荐区域内部的特征图被提取作为一个固定的输出。SPPnet在训练阶段加速了10倍以上，测试阶段速度提升了3倍。

SPPnet最大的缺点是它是多阶段的，抽取特征、用逻辑损失条件网络、训练SVM最后拟合边框回归。



## 1.1 贡献

我们提出了一种新的训练算法解决了以上的缺点，同时提高了速度和准确率。它有以下的优势：

- 用多任务损失，训练是单阶段的
- 训练可以更新所有的网络层
- 不需要磁盘存储特征缓存

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-11-19_20-29-47.png)

​	图一展示了把整张图和一系列推荐区域作为输入，这个网络首先通过卷积层和池化层处理整张图片产生一个卷积特征图。然后，对于每个标签出的图片中的物体，RoI pooling层会从feature map中提取一个固定长度的特征向量，用于接下来的全联接层来产生两个分支：一个是：softmax概率来预测（k+1-背景)个类别。另一个是对于每个属于k个类别的物体，产生四个数字来调节边框。

## 2.1 RoI 池化层

​	RoI池化层使用最大池化将任何有效感兴趣区域内的特征转换为具有固定空间范围H×W（例如，7×7）的小特征映射，其中H和W是层超参数 这与任何特定的RoI无关。 在本文中，RoI是一个转换为转换特征映射的矩形窗口。 每个RoI由四元组（r，c，h，w）定义，指定其左上角（r，c）及其高度和宽度（h，w）。

​	RoI max pooling通过将h×w RoI窗口划分为大约h / H×w / W的子窗口的H×W网格，然后将每个子窗口中的最大值映射到相应的输出网格单元。 池化独立应用于每个要素图通道。 RoI层只是SPPnets 中使用的空间金字塔池层的特例，其中只有一个金字塔层。

## 2.2 从预先训练的网络初始化

​	我们试验了三个经过预先训练的ImageNet网络，每个网络有五个最大池化层和五到十三个卷积层。 当预训练的网络初始化fast R-CNN网络时，它经历三次转换。
​	首先，最后的最大池化层被RoI池化层替换，该池化层通过对H和W的设置来匹配网络的第一个完全连接层（例如，H = W = 7 for VGG16）。
​	其次，网络的最后一个完全连接层和softmax层（被训练为1000个ImageNet分类）被前面描述的两个兄弟层替换（一个带有softmax的完全连接的层（K + 1类别分类）和 特定类别的边界框回归）。
​	第三，修改网络以获取两个数据输入：图像列表和那些图像中的RoI列表。

## 2.3 微调检测

​	使用反向传播训练所有网络权重是fast R-CNN的重要功能。 首先，让我们阐明为什么SPPnet无法更新空间金字塔池化层下的权重。
​	根本原因是当每个训练样本（即RoI）来自不同的图像时，通过SPP层的反向传播非常低效，这正是R-CNN和SPPnet网络的训练方式。 每个RoI可能具有非常大的感受野，低效的系统通常跨越扫描整个输入图像。 由于前向传球必须处理整个感受野，因此训练输入很大（通常是整个图像）。

​	我们提出了一种更有效的训练方法，即利用训练期间的特征共享。在fast R-CNN训练中，随机梯度下降（SGD）那些分层采样的小批量样本，首先采样N个图像，然后从每个图像中采样R / N 个RoI。重要的是，来自相同图像的RoI在前向和后向传递中共享计算和内存。例如，当使用N = 2且R = 128时，所提出的训练方案比从128个不同图像分别采样一个RoI（即，R-CNN和SPPnet策略）快64倍。
​	对此策略的一个担忧是它可能导致慢速训练收敛，因为来自同一图像的那些RoI是彼此相关的。这个问题似乎不是一个实际问题，我们使用比R-CNN更少的SGD迭代，（设置N = 2和R = 128）却获得了良好的结果。
​	除了分层采样之外，Fast R-CNN使用简化的训练过程（只有一个微调阶段），同时优化了softmax分类器和边界回归器，而不是在三个单独的阶段训练softmax分类器，SVM和回归器。该程序的组成部分（损失，小批量采样策略，通过RoI池化层的反向传播和SGD超参数）如下所述。

**多任务损失**。fast rcnn 有两个兄弟输出。第一个输出是一个离散概率分布（per RoI) p=($p_1 ,p_2,...,p_k $),表示（k+1)个类。p是经过全联接层后softmax的输出。第二个输出是边框回归的偏移。每个K对象类，用k索引。

$t^k = (t_x^k, t_y^k, t_w^k, t_h^k)$   我们使用$t_k$的参数化，其中$t_k$指定相对于对象推荐区域的尺度不变的平移和对数空间高度/宽度偏移。

每个训练的RoI都标有实际的类u,和实际的边界框回归目标v。我们在每个标记的RoI上使用多任务损失L来联合训练分类和边界框回归：
$L（p，u，t^u，v）= L_{cls}（p，u）+λ[u≥1] L_{loc}（t^u，v）$

其中$L_{cls}(p, u) = -log p_u$ 是实际类别u的分类损失。

$对于一个分类u, v=(v_x, v_y, v_w, v_h), 它对应的预测为t^u = (t_x^u, t_y^u, t_w^u, t_h^u)$

$L_{loc}(t^u, v) = \sum smooth_{L_1}(t_i^u-v_i),$

$in \ which, \ \ smooth_{L_1}(x) = \bigg\{_{|x| - 0.5 otherwise}^{0.5x^2   \ \ \   if|x|<1 }$

我们通过方差为1，均值为0，标准化所有v,所以设置超参数为 $\gamma = 1$ 

**通过roi 池化层的反向传播** 简明起见，我们假设每次小批量设置N=1，只考虑一张图片。即使设置N>1时，因为前向传播是对每张图片是单独训练的，所以原理相同。

$x_i$代表第i个激活层输入，$y_{rj}$是这第r个roi层的第j个输出。

roi 池化层计算$y_{rj} = x_{i*(r, j)}. 其中 i*(r,j) = argmax X_{i′∈R(r,j) } $

R(r, j)是$y_{rj}$最大池化输出单元的子窗口的输入的索引集， 一个$x_i$ 可能被分配到几个不同的输出$y_{rj}$.





​	



